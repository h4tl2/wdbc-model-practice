{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      "id                         569 non-null int64\n",
      "diagnosis                  569 non-null object\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "Unnamed: 32                0 non-null float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dropping the unused column\n",
    "data.drop(\"Unnamed: 32\",axis=1,inplace=True)\n",
    "data.drop(\"id\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "B    357\n",
       "M    212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('diagnosis').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10c2bd588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAFsCAYAAAD7SMNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+cYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111268e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = data.corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.170581</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>-0.311631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.007066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.323782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.119205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.051019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>-0.283110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.003738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>0.170581</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>0.584792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.499316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.565369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.687382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>0.336783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.514930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.368661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>0.147741</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>0.438413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>-0.311631</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>-0.283110</td>\n",
       "      <td>0.584792</td>\n",
       "      <td>0.565369</td>\n",
       "      <td>0.336783</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>0.479921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.051269</td>\n",
       "      <td>-0.205151</td>\n",
       "      <td>-0.231854</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>0.767297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>0.679090</td>\n",
       "      <td>0.275869</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.301467</td>\n",
       "      <td>0.497473</td>\n",
       "      <td>0.631925</td>\n",
       "      <td>0.698050</td>\n",
       "      <td>0.303379</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715065</td>\n",
       "      <td>0.194799</td>\n",
       "      <td>0.719684</td>\n",
       "      <td>0.751548</td>\n",
       "      <td>0.141919</td>\n",
       "      <td>0.287103</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>0.531062</td>\n",
       "      <td>0.094543</td>\n",
       "      <td>0.049559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>-0.097317</td>\n",
       "      <td>0.386358</td>\n",
       "      <td>-0.086761</td>\n",
       "      <td>-0.066280</td>\n",
       "      <td>0.068406</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.076218</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.128053</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111690</td>\n",
       "      <td>0.409003</td>\n",
       "      <td>-0.102242</td>\n",
       "      <td>-0.083195</td>\n",
       "      <td>-0.073658</td>\n",
       "      <td>-0.092439</td>\n",
       "      <td>-0.068956</td>\n",
       "      <td>-0.119638</td>\n",
       "      <td>-0.128215</td>\n",
       "      <td>-0.045655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>0.674172</td>\n",
       "      <td>0.281673</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>0.726628</td>\n",
       "      <td>0.296092</td>\n",
       "      <td>0.548905</td>\n",
       "      <td>0.660391</td>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.313893</td>\n",
       "      <td>0.039830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>0.200371</td>\n",
       "      <td>0.721031</td>\n",
       "      <td>0.730713</td>\n",
       "      <td>0.130054</td>\n",
       "      <td>0.341919</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.554897</td>\n",
       "      <td>0.109930</td>\n",
       "      <td>0.085433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>0.735864</td>\n",
       "      <td>0.259845</td>\n",
       "      <td>0.744983</td>\n",
       "      <td>0.800086</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.455653</td>\n",
       "      <td>0.617427</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.223970</td>\n",
       "      <td>-0.090170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757373</td>\n",
       "      <td>0.196497</td>\n",
       "      <td>0.761213</td>\n",
       "      <td>0.811408</td>\n",
       "      <td>0.125389</td>\n",
       "      <td>0.283257</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.538166</td>\n",
       "      <td>0.074126</td>\n",
       "      <td>0.017539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>-0.222600</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>-0.202694</td>\n",
       "      <td>-0.166777</td>\n",
       "      <td>0.332375</td>\n",
       "      <td>0.135299</td>\n",
       "      <td>0.098564</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>0.187321</td>\n",
       "      <td>0.401964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230691</td>\n",
       "      <td>-0.074743</td>\n",
       "      <td>-0.217304</td>\n",
       "      <td>-0.182195</td>\n",
       "      <td>0.314457</td>\n",
       "      <td>-0.055558</td>\n",
       "      <td>-0.058298</td>\n",
       "      <td>-0.102007</td>\n",
       "      <td>-0.107342</td>\n",
       "      <td>0.101480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.191975</td>\n",
       "      <td>0.250744</td>\n",
       "      <td>0.212583</td>\n",
       "      <td>0.318943</td>\n",
       "      <td>0.738722</td>\n",
       "      <td>0.670279</td>\n",
       "      <td>0.490424</td>\n",
       "      <td>0.421659</td>\n",
       "      <td>0.559837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204607</td>\n",
       "      <td>0.143003</td>\n",
       "      <td>0.260516</td>\n",
       "      <td>0.199371</td>\n",
       "      <td>0.227394</td>\n",
       "      <td>0.678780</td>\n",
       "      <td>0.639147</td>\n",
       "      <td>0.483208</td>\n",
       "      <td>0.277878</td>\n",
       "      <td>0.590973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>0.194204</td>\n",
       "      <td>0.143293</td>\n",
       "      <td>0.228082</td>\n",
       "      <td>0.207660</td>\n",
       "      <td>0.248396</td>\n",
       "      <td>0.570517</td>\n",
       "      <td>0.691270</td>\n",
       "      <td>0.439167</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>0.446630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186904</td>\n",
       "      <td>0.100241</td>\n",
       "      <td>0.226680</td>\n",
       "      <td>0.188353</td>\n",
       "      <td>0.168481</td>\n",
       "      <td>0.484858</td>\n",
       "      <td>0.662564</td>\n",
       "      <td>0.440472</td>\n",
       "      <td>0.197788</td>\n",
       "      <td>0.439329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>0.376169</td>\n",
       "      <td>0.163851</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.372320</td>\n",
       "      <td>0.380676</td>\n",
       "      <td>0.642262</td>\n",
       "      <td>0.683260</td>\n",
       "      <td>0.615634</td>\n",
       "      <td>0.393298</td>\n",
       "      <td>0.341198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358127</td>\n",
       "      <td>0.086741</td>\n",
       "      <td>0.394999</td>\n",
       "      <td>0.342271</td>\n",
       "      <td>0.215351</td>\n",
       "      <td>0.452888</td>\n",
       "      <td>0.549592</td>\n",
       "      <td>0.602450</td>\n",
       "      <td>0.143116</td>\n",
       "      <td>0.310655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>-0.104321</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>-0.081629</td>\n",
       "      <td>-0.072497</td>\n",
       "      <td>0.200774</td>\n",
       "      <td>0.229977</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>0.095351</td>\n",
       "      <td>0.449137</td>\n",
       "      <td>0.345007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128121</td>\n",
       "      <td>-0.077473</td>\n",
       "      <td>-0.103753</td>\n",
       "      <td>-0.110343</td>\n",
       "      <td>-0.012662</td>\n",
       "      <td>0.060255</td>\n",
       "      <td>0.037119</td>\n",
       "      <td>-0.030413</td>\n",
       "      <td>0.389402</td>\n",
       "      <td>0.078079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>-0.042641</td>\n",
       "      <td>0.054458</td>\n",
       "      <td>-0.005523</td>\n",
       "      <td>-0.019887</td>\n",
       "      <td>0.283607</td>\n",
       "      <td>0.507318</td>\n",
       "      <td>0.449301</td>\n",
       "      <td>0.257584</td>\n",
       "      <td>0.331786</td>\n",
       "      <td>0.688132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037488</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.022736</td>\n",
       "      <td>0.170568</td>\n",
       "      <td>0.390159</td>\n",
       "      <td>0.379975</td>\n",
       "      <td>0.215204</td>\n",
       "      <td>0.111094</td>\n",
       "      <td>0.591328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359921</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.216574</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.093492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>-0.051269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.219122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>-0.205151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.138957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>-0.231854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.079647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216574</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.617624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.810455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.686511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>0.511114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.051019</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.499316</td>\n",
       "      <td>0.687382</td>\n",
       "      <td>0.514930</td>\n",
       "      <td>0.368661</td>\n",
       "      <td>0.438413</td>\n",
       "      <td>0.767297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093492</td>\n",
       "      <td>0.219122</td>\n",
       "      <td>0.138957</td>\n",
       "      <td>0.079647</td>\n",
       "      <td>0.617624</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>0.686511</td>\n",
       "      <td>0.511114</td>\n",
       "      <td>0.537848</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "radius_mean                 1.000000      0.323782        0.997855   0.987357   \n",
       "texture_mean                0.323782      1.000000        0.329533   0.321086   \n",
       "perimeter_mean              0.997855      0.329533        1.000000   0.986507   \n",
       "area_mean                   0.987357      0.321086        0.986507   1.000000   \n",
       "smoothness_mean             0.170581     -0.023389        0.207278   0.177028   \n",
       "compactness_mean            0.506124      0.236702        0.556936   0.498502   \n",
       "concavity_mean              0.676764      0.302418        0.716136   0.685983   \n",
       "concave points_mean         0.822529      0.293464        0.850977   0.823269   \n",
       "symmetry_mean               0.147741      0.071401        0.183027   0.151293   \n",
       "fractal_dimension_mean     -0.311631     -0.076437       -0.261477  -0.283110   \n",
       "radius_se                   0.679090      0.275869        0.691765   0.732562   \n",
       "texture_se                 -0.097317      0.386358       -0.086761  -0.066280   \n",
       "perimeter_se                0.674172      0.281673        0.693135   0.726628   \n",
       "area_se                     0.735864      0.259845        0.744983   0.800086   \n",
       "smoothness_se              -0.222600      0.006614       -0.202694  -0.166777   \n",
       "compactness_se              0.206000      0.191975        0.250744   0.212583   \n",
       "concavity_se                0.194204      0.143293        0.228082   0.207660   \n",
       "concave points_se           0.376169      0.163851        0.407217   0.372320   \n",
       "symmetry_se                -0.104321      0.009127       -0.081629  -0.072497   \n",
       "fractal_dimension_se       -0.042641      0.054458       -0.005523  -0.019887   \n",
       "radius_worst                0.969539      0.352573        0.969476   0.962746   \n",
       "texture_worst               0.297008      0.912045        0.303038   0.287489   \n",
       "perimeter_worst             0.965137      0.358040        0.970387   0.959120   \n",
       "area_worst                  0.941082      0.343546        0.941550   0.959213   \n",
       "smoothness_worst            0.119616      0.077503        0.150549   0.123523   \n",
       "compactness_worst           0.413463      0.277830        0.455774   0.390410   \n",
       "concavity_worst             0.526911      0.301025        0.563879   0.512606   \n",
       "concave points_worst        0.744214      0.295316        0.771241   0.722017   \n",
       "symmetry_worst              0.163953      0.105008        0.189115   0.143570   \n",
       "fractal_dimension_worst     0.007066      0.119205        0.051019   0.003738   \n",
       "\n",
       "                         smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "radius_mean                     0.170581          0.506124        0.676764   \n",
       "texture_mean                   -0.023389          0.236702        0.302418   \n",
       "perimeter_mean                  0.207278          0.556936        0.716136   \n",
       "area_mean                       0.177028          0.498502        0.685983   \n",
       "smoothness_mean                 1.000000          0.659123        0.521984   \n",
       "compactness_mean                0.659123          1.000000        0.883121   \n",
       "concavity_mean                  0.521984          0.883121        1.000000   \n",
       "concave points_mean             0.553695          0.831135        0.921391   \n",
       "symmetry_mean                   0.557775          0.602641        0.500667   \n",
       "fractal_dimension_mean          0.584792          0.565369        0.336783   \n",
       "radius_se                       0.301467          0.497473        0.631925   \n",
       "texture_se                      0.068406          0.046205        0.076218   \n",
       "perimeter_se                    0.296092          0.548905        0.660391   \n",
       "area_se                         0.246552          0.455653        0.617427   \n",
       "smoothness_se                   0.332375          0.135299        0.098564   \n",
       "compactness_se                  0.318943          0.738722        0.670279   \n",
       "concavity_se                    0.248396          0.570517        0.691270   \n",
       "concave points_se               0.380676          0.642262        0.683260   \n",
       "symmetry_se                     0.200774          0.229977        0.178009   \n",
       "fractal_dimension_se            0.283607          0.507318        0.449301   \n",
       "radius_worst                    0.213120          0.535315        0.688236   \n",
       "texture_worst                   0.036072          0.248133        0.299879   \n",
       "perimeter_worst                 0.238853          0.590210        0.729565   \n",
       "area_worst                      0.206718          0.509604        0.675987   \n",
       "smoothness_worst                0.805324          0.565541        0.448822   \n",
       "compactness_worst               0.472468          0.865809        0.754968   \n",
       "concavity_worst                 0.434926          0.816275        0.884103   \n",
       "concave points_worst            0.503053          0.815573        0.861323   \n",
       "symmetry_worst                  0.394309          0.510223        0.409464   \n",
       "fractal_dimension_worst         0.499316          0.687382        0.514930   \n",
       "\n",
       "                         concave points_mean  symmetry_mean  \\\n",
       "radius_mean                         0.822529       0.147741   \n",
       "texture_mean                        0.293464       0.071401   \n",
       "perimeter_mean                      0.850977       0.183027   \n",
       "area_mean                           0.823269       0.151293   \n",
       "smoothness_mean                     0.553695       0.557775   \n",
       "compactness_mean                    0.831135       0.602641   \n",
       "concavity_mean                      0.921391       0.500667   \n",
       "concave points_mean                 1.000000       0.462497   \n",
       "symmetry_mean                       0.462497       1.000000   \n",
       "fractal_dimension_mean              0.166917       0.479921   \n",
       "radius_se                           0.698050       0.303379   \n",
       "texture_se                          0.021480       0.128053   \n",
       "perimeter_se                        0.710650       0.313893   \n",
       "area_se                             0.690299       0.223970   \n",
       "smoothness_se                       0.027653       0.187321   \n",
       "compactness_se                      0.490424       0.421659   \n",
       "concavity_se                        0.439167       0.342627   \n",
       "concave points_se                   0.615634       0.393298   \n",
       "symmetry_se                         0.095351       0.449137   \n",
       "fractal_dimension_se                0.257584       0.331786   \n",
       "radius_worst                        0.830318       0.185728   \n",
       "texture_worst                       0.292752       0.090651   \n",
       "perimeter_worst                     0.855923       0.219169   \n",
       "area_worst                          0.809630       0.177193   \n",
       "smoothness_worst                    0.452753       0.426675   \n",
       "compactness_worst                   0.667454       0.473200   \n",
       "concavity_worst                     0.752399       0.433721   \n",
       "concave points_worst                0.910155       0.430297   \n",
       "symmetry_worst                      0.375744       0.699826   \n",
       "fractal_dimension_worst             0.368661       0.438413   \n",
       "\n",
       "                         fractal_dimension_mean           ...             \\\n",
       "radius_mean                           -0.311631           ...              \n",
       "texture_mean                          -0.076437           ...              \n",
       "perimeter_mean                        -0.261477           ...              \n",
       "area_mean                             -0.283110           ...              \n",
       "smoothness_mean                        0.584792           ...              \n",
       "compactness_mean                       0.565369           ...              \n",
       "concavity_mean                         0.336783           ...              \n",
       "concave points_mean                    0.166917           ...              \n",
       "symmetry_mean                          0.479921           ...              \n",
       "fractal_dimension_mean                 1.000000           ...              \n",
       "radius_se                              0.000111           ...              \n",
       "texture_se                             0.164174           ...              \n",
       "perimeter_se                           0.039830           ...              \n",
       "area_se                               -0.090170           ...              \n",
       "smoothness_se                          0.401964           ...              \n",
       "compactness_se                         0.559837           ...              \n",
       "concavity_se                           0.446630           ...              \n",
       "concave points_se                      0.341198           ...              \n",
       "symmetry_se                            0.345007           ...              \n",
       "fractal_dimension_se                   0.688132           ...              \n",
       "radius_worst                          -0.253691           ...              \n",
       "texture_worst                         -0.051269           ...              \n",
       "perimeter_worst                       -0.205151           ...              \n",
       "area_worst                            -0.231854           ...              \n",
       "smoothness_worst                       0.504942           ...              \n",
       "compactness_worst                      0.458798           ...              \n",
       "concavity_worst                        0.346234           ...              \n",
       "concave points_worst                   0.175325           ...              \n",
       "symmetry_worst                         0.334019           ...              \n",
       "fractal_dimension_worst                0.767297           ...              \n",
       "\n",
       "                         radius_worst  texture_worst  perimeter_worst  \\\n",
       "radius_mean                  0.969539       0.297008         0.965137   \n",
       "texture_mean                 0.352573       0.912045         0.358040   \n",
       "perimeter_mean               0.969476       0.303038         0.970387   \n",
       "area_mean                    0.962746       0.287489         0.959120   \n",
       "smoothness_mean              0.213120       0.036072         0.238853   \n",
       "compactness_mean             0.535315       0.248133         0.590210   \n",
       "concavity_mean               0.688236       0.299879         0.729565   \n",
       "concave points_mean          0.830318       0.292752         0.855923   \n",
       "symmetry_mean                0.185728       0.090651         0.219169   \n",
       "fractal_dimension_mean      -0.253691      -0.051269        -0.205151   \n",
       "radius_se                    0.715065       0.194799         0.719684   \n",
       "texture_se                  -0.111690       0.409003        -0.102242   \n",
       "perimeter_se                 0.697201       0.200371         0.721031   \n",
       "area_se                      0.757373       0.196497         0.761213   \n",
       "smoothness_se               -0.230691      -0.074743        -0.217304   \n",
       "compactness_se               0.204607       0.143003         0.260516   \n",
       "concavity_se                 0.186904       0.100241         0.226680   \n",
       "concave points_se            0.358127       0.086741         0.394999   \n",
       "symmetry_se                 -0.128121      -0.077473        -0.103753   \n",
       "fractal_dimension_se        -0.037488      -0.003195        -0.001000   \n",
       "radius_worst                 1.000000       0.359921         0.993708   \n",
       "texture_worst                0.359921       1.000000         0.365098   \n",
       "perimeter_worst              0.993708       0.365098         1.000000   \n",
       "area_worst                   0.984015       0.345842         0.977578   \n",
       "smoothness_worst             0.216574       0.225429         0.236775   \n",
       "compactness_worst            0.475820       0.360832         0.529408   \n",
       "concavity_worst              0.573975       0.368366         0.618344   \n",
       "concave points_worst         0.787424       0.359755         0.816322   \n",
       "symmetry_worst               0.243529       0.233027         0.269493   \n",
       "fractal_dimension_worst      0.093492       0.219122         0.138957   \n",
       "\n",
       "                         area_worst  smoothness_worst  compactness_worst  \\\n",
       "radius_mean                0.941082          0.119616           0.413463   \n",
       "texture_mean               0.343546          0.077503           0.277830   \n",
       "perimeter_mean             0.941550          0.150549           0.455774   \n",
       "area_mean                  0.959213          0.123523           0.390410   \n",
       "smoothness_mean            0.206718          0.805324           0.472468   \n",
       "compactness_mean           0.509604          0.565541           0.865809   \n",
       "concavity_mean             0.675987          0.448822           0.754968   \n",
       "concave points_mean        0.809630          0.452753           0.667454   \n",
       "symmetry_mean              0.177193          0.426675           0.473200   \n",
       "fractal_dimension_mean    -0.231854          0.504942           0.458798   \n",
       "radius_se                  0.751548          0.141919           0.287103   \n",
       "texture_se                -0.083195         -0.073658          -0.092439   \n",
       "perimeter_se               0.730713          0.130054           0.341919   \n",
       "area_se                    0.811408          0.125389           0.283257   \n",
       "smoothness_se             -0.182195          0.314457          -0.055558   \n",
       "compactness_se             0.199371          0.227394           0.678780   \n",
       "concavity_se               0.188353          0.168481           0.484858   \n",
       "concave points_se          0.342271          0.215351           0.452888   \n",
       "symmetry_se               -0.110343         -0.012662           0.060255   \n",
       "fractal_dimension_se      -0.022736          0.170568           0.390159   \n",
       "radius_worst               0.984015          0.216574           0.475820   \n",
       "texture_worst              0.345842          0.225429           0.360832   \n",
       "perimeter_worst            0.977578          0.236775           0.529408   \n",
       "area_worst                 1.000000          0.209145           0.438296   \n",
       "smoothness_worst           0.209145          1.000000           0.568187   \n",
       "compactness_worst          0.438296          0.568187           1.000000   \n",
       "concavity_worst            0.543331          0.518523           0.892261   \n",
       "concave points_worst       0.747419          0.547691           0.801080   \n",
       "symmetry_worst             0.209146          0.493838           0.614441   \n",
       "fractal_dimension_worst    0.079647          0.617624           0.810455   \n",
       "\n",
       "                         concavity_worst  concave points_worst  \\\n",
       "radius_mean                     0.526911              0.744214   \n",
       "texture_mean                    0.301025              0.295316   \n",
       "perimeter_mean                  0.563879              0.771241   \n",
       "area_mean                       0.512606              0.722017   \n",
       "smoothness_mean                 0.434926              0.503053   \n",
       "compactness_mean                0.816275              0.815573   \n",
       "concavity_mean                  0.884103              0.861323   \n",
       "concave points_mean             0.752399              0.910155   \n",
       "symmetry_mean                   0.433721              0.430297   \n",
       "fractal_dimension_mean          0.346234              0.175325   \n",
       "radius_se                       0.380585              0.531062   \n",
       "texture_se                     -0.068956             -0.119638   \n",
       "perimeter_se                    0.418899              0.554897   \n",
       "area_se                         0.385100              0.538166   \n",
       "smoothness_se                  -0.058298             -0.102007   \n",
       "compactness_se                  0.639147              0.483208   \n",
       "concavity_se                    0.662564              0.440472   \n",
       "concave points_se               0.549592              0.602450   \n",
       "symmetry_se                     0.037119             -0.030413   \n",
       "fractal_dimension_se            0.379975              0.215204   \n",
       "radius_worst                    0.573975              0.787424   \n",
       "texture_worst                   0.368366              0.359755   \n",
       "perimeter_worst                 0.618344              0.816322   \n",
       "area_worst                      0.543331              0.747419   \n",
       "smoothness_worst                0.518523              0.547691   \n",
       "compactness_worst               0.892261              0.801080   \n",
       "concavity_worst                 1.000000              0.855434   \n",
       "concave points_worst            0.855434              1.000000   \n",
       "symmetry_worst                  0.532520              0.502528   \n",
       "fractal_dimension_worst         0.686511              0.511114   \n",
       "\n",
       "                         symmetry_worst  fractal_dimension_worst  \n",
       "radius_mean                    0.163953                 0.007066  \n",
       "texture_mean                   0.105008                 0.119205  \n",
       "perimeter_mean                 0.189115                 0.051019  \n",
       "area_mean                      0.143570                 0.003738  \n",
       "smoothness_mean                0.394309                 0.499316  \n",
       "compactness_mean               0.510223                 0.687382  \n",
       "concavity_mean                 0.409464                 0.514930  \n",
       "concave points_mean            0.375744                 0.368661  \n",
       "symmetry_mean                  0.699826                 0.438413  \n",
       "fractal_dimension_mean         0.334019                 0.767297  \n",
       "radius_se                      0.094543                 0.049559  \n",
       "texture_se                    -0.128215                -0.045655  \n",
       "perimeter_se                   0.109930                 0.085433  \n",
       "area_se                        0.074126                 0.017539  \n",
       "smoothness_se                 -0.107342                 0.101480  \n",
       "compactness_se                 0.277878                 0.590973  \n",
       "concavity_se                   0.197788                 0.439329  \n",
       "concave points_se              0.143116                 0.310655  \n",
       "symmetry_se                    0.389402                 0.078079  \n",
       "fractal_dimension_se           0.111094                 0.591328  \n",
       "radius_worst                   0.243529                 0.093492  \n",
       "texture_worst                  0.233027                 0.219122  \n",
       "perimeter_worst                0.269493                 0.138957  \n",
       "area_worst                     0.209146                 0.079647  \n",
       "smoothness_worst               0.493838                 0.617624  \n",
       "compactness_worst              0.614441                 0.810455  \n",
       "concavity_worst                0.532520                 0.686511  \n",
       "concave points_worst           0.502528                 0.511114  \n",
       "symmetry_worst                 1.000000                 0.537848  \n",
       "fractal_dimension_worst        0.537848                 1.000000  \n",
       "\n",
       "[30 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = data.diagnosis.values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['B', 'M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dropping the y column from x\n",
    "x = data.drop(['diagnosis'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean           ...             radius_worst  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(x, y, \n",
    "                     test_size=0.20,\n",
    "                     stratify=y,\n",
    "                     random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply StandardScaler and Pca to the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "stdsc = StandardScaler()\n",
    "pca = PCA()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "x_train = pca.fit_transform(X_train_std)\n",
    "x_test = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_train,y_train)\n",
    "predicted_log = logmodel.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99        72\n",
      "          1       0.98      0.98      0.98        42\n",
      "\n",
      "avg / total       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predicted_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)\n",
    "predicted_tree = tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92        72\n",
      "          1       0.84      0.90      0.87        42\n",
      "\n",
      "avg / total       0.91      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicted_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.94      0.96        72\n",
      "          1       0.91      0.95      0.93        42\n",
      "\n",
      "avg / total       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train,y_train)\n",
    "predicted_rfc = rfc.predict(x_test)\n",
    "print(classification_report(y_test,predicted_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97        72\n",
      "          1       0.95      0.93      0.94        42\n",
      "\n",
      "avg / total       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(x_train,y_train)\n",
    "predicted_ada = ada.predict(x_test)\n",
    "print(classification_report(y_test,predicted_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ad_train = ada.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform GridSearchCV to find suitable parameters\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824175824175824\n",
      "{'logisticregression__C': 0.1}\n",
      "0.9582417582417583\n",
      "{'decisiontreeclassifier__max_depth': 4, 'decisiontreeclassifier__min_samples_leaf': 4}\n",
      "0.9626373626373627\n",
      "{'randomforestclassifier__max_depth': 7, 'randomforestclassifier__min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "#pipeline for logistic regression\n",
    "pipe_lr = make_pipeline(LogisticRegression(random_state=1))\n",
    "\n",
    "param_grid_lr = [{'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}]\n",
    "\n",
    "gs_lr = GridSearchCV(estimator=pipe_lr, \n",
    "                  param_grid=param_grid_lr, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  refit=True)\n",
    "\n",
    "gs_lr = gs_lr.fit(x_train, y_train)\n",
    "\n",
    "print(gs_lr.best_score_)\n",
    "print(gs_lr.best_params_)\n",
    "\n",
    "#pipeline for decision tree\n",
    "pipe_dt = make_pipeline(DecisionTreeClassifier(random_state=1))\n",
    "\n",
    "param_grid_dt = [{'decisiontreeclassifier__max_depth': [1, 2, 3, 4, 5, 6, 7, None], \n",
    "               'decisiontreeclassifier__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7]}]\n",
    "\n",
    "gs_dt = GridSearchCV(estimator=pipe_dt,\n",
    "                  param_grid=param_grid_dt,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10,\n",
    "                  refit=True)\n",
    "\n",
    "gs_dt = gs_dt.fit(X_train_std, y_train)\n",
    "\n",
    "print(gs_dt.best_score_)\n",
    "print(gs_dt.best_params_)\n",
    "\n",
    "#pipeline for ensemble (RFC)\n",
    "pipe_rf = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "param_grid_rf = [{'randomforestclassifier__max_depth': [1, 2, 3, 4, 5, 6, 7, None], \n",
    "               'randomforestclassifier__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7]}]\n",
    "\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "                  param_grid=param_grid_rf,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10,\n",
    "                  refit=True)\n",
    "\n",
    "gs_rf = gs_rf.fit(X_train_std, y_train)\n",
    "\n",
    "print(gs_rf.best_score_)\n",
    "print(gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pick best est\n",
    "best_lr = gs_lr.best_estimator_\n",
    "best_dt = gs_dt.best_estimator_\n",
    "best_rf = gs_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict using best est\n",
    "y_pred_lr_test = best_lr.predict(x_test)\n",
    "y_pred_dt_test = best_dt.predict(X_test_std)\n",
    "y_pred_rf_test = best_rf.predict(X_test_std)\n",
    "\n",
    "y_pred_lr_train = best_lr.predict(x_train)\n",
    "y_pred_dt_train = best_dt.predict(X_train_std)\n",
    "y_pred_rf_train = best_rf.predict(X_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Train data\n",
      "Logistic Regression Train Accuracy: 0.987\n",
      "Decision Tree Train Accuracy: 0.985\n",
      "Random Forest Train Accuracy: 0.991\n",
      "\n",
      "Accuracy on Test data\n",
      "Logistic Regression Test Accuracy: 0.982\n",
      "Decision Tree Test Accuracy: 0.939\n",
      "Random Forest Train Accuracy: 0.956\n",
      "Adaboost Train Accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Train data\")\n",
    "print('Logistic Regression Train Accuracy: %.3f' % accuracy_score(y_true=y_train, y_pred=y_pred_lr_train))\n",
    "print('Decision Tree Train Accuracy: %.3f' % accuracy_score(y_true=y_train, y_pred=y_pred_dt_train))\n",
    "print('Random Forest Train Accuracy: %.3f' % accuracy_score(y_true=y_train, y_pred=y_pred_rf_train))\n",
    "print('')\n",
    "print(\"Accuracy on Test data\")\n",
    "print('Logistic Regression Test Accuracy: %.3f' % accuracy_score(y_true=y_test, y_pred=y_pred_lr_test))\n",
    "print('Decision Tree Test Accuracy: %.3f' % accuracy_score(y_true=y_test, y_pred=y_pred_dt_test))\n",
    "print('Random Forest Train Accuracy: %.3f' % accuracy_score(y_true=y_test, y_pred=y_pred_rf_test))\n",
    "print('Adaboost Train Accuracy: %.3f' % accuracy_score(y_true=y_test, y_pred=predicted_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Logistic Regression --\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99        72\n",
      "          1       0.98      0.98      0.98        42\n",
      "\n",
      "avg / total       0.98      0.98      0.98       114\n",
      "\n",
      "-- Decision Tree --\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.95        72\n",
      "          1       0.93      0.90      0.92        42\n",
      "\n",
      "avg / total       0.94      0.94      0.94       114\n",
      "\n",
      "-- Random Forest --\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97        72\n",
      "          1       0.97      0.90      0.94        42\n",
      "\n",
      "avg / total       0.96      0.96      0.96       114\n",
      "\n",
      "-- AdaBoost --\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97        72\n",
      "          1       0.95      0.93      0.94        42\n",
      "\n",
      "avg / total       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-- Logistic Regression --')\n",
    "print(classification_report(y_test,y_pred_lr_test))\n",
    "print('-- Decision Tree --')\n",
    "print(classification_report(y_test,y_pred_dt_test))\n",
    "print('-- Random Forest --')\n",
    "print(classification_report(y_test,y_pred_rf_test))\n",
    "print('-- AdaBoost --')\n",
    "print(classification_report(y_test,predicted_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=30, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/20\n",
      " - 0s - loss: 0.8230 - acc: 0.5165 - val_loss: 0.7126 - val_acc: 0.5351\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.7459 - acc: 0.5692 - val_loss: 0.6773 - val_acc: 0.7193\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.7190 - acc: 0.6879 - val_loss: 0.6462 - val_acc: 0.7719\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6928 - acc: 0.6791 - val_loss: 0.6274 - val_acc: 0.8158\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.6766 - acc: 0.7341 - val_loss: 0.6043 - val_acc: 0.8509\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.6479 - acc: 0.7495 - val_loss: 0.5825 - val_acc: 0.8772\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.6099 - acc: 0.7538 - val_loss: 0.5645 - val_acc: 0.8947\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.5805 - acc: 0.8000 - val_loss: 0.5416 - val_acc: 0.9211\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.5848 - acc: 0.7758 - val_loss: 0.5201 - val_acc: 0.9386\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.5370 - acc: 0.8176 - val_loss: 0.4970 - val_acc: 0.9386\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.5236 - acc: 0.8286 - val_loss: 0.4719 - val_acc: 0.9386\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.5059 - acc: 0.8374 - val_loss: 0.4480 - val_acc: 0.9474\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.4632 - acc: 0.8901 - val_loss: 0.4193 - val_acc: 0.9474\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.4373 - acc: 0.8681 - val_loss: 0.3933 - val_acc: 0.9386\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.4288 - acc: 0.8725 - val_loss: 0.3694 - val_acc: 0.9386\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.3984 - acc: 0.9011 - val_loss: 0.3439 - val_acc: 0.9386\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.3662 - acc: 0.9099 - val_loss: 0.3173 - val_acc: 0.9386\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.3410 - acc: 0.8967 - val_loss: 0.2947 - val_acc: 0.9474\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.3376 - acc: 0.9231 - val_loss: 0.2724 - val_acc: 0.9474\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.3075 - acc: 0.9209 - val_loss: 0.2525 - val_acc: 0.9474\n",
      "114/114 [==============================] - 0s 88us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=50,\n",
    "         validation_data=(x_test, y_test),verbose=2)\n",
    "score, acc  = model.evaluate(x_test, y_test, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.2524680709629728\n",
      "Test accuracy: 0.9473684189612406\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=30, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/20\n",
      " - 0s - loss: 0.5793 - acc: 0.7055 - val_loss: 0.4989 - val_acc: 0.7895\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.4791 - acc: 0.8088 - val_loss: 0.4250 - val_acc: 0.8860\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.4112 - acc: 0.8637 - val_loss: 0.3691 - val_acc: 0.9035\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.3572 - acc: 0.8967 - val_loss: 0.3235 - val_acc: 0.9211\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.3124 - acc: 0.9209 - val_loss: 0.2811 - val_acc: 0.9298\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.2720 - acc: 0.9473 - val_loss: 0.2472 - val_acc: 0.9386\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.2406 - acc: 0.9538 - val_loss: 0.2227 - val_acc: 0.9386\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.2161 - acc: 0.9604 - val_loss: 0.1988 - val_acc: 0.9561\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.1926 - acc: 0.9626 - val_loss: 0.1793 - val_acc: 0.9649\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.1733 - acc: 0.9648 - val_loss: 0.1606 - val_acc: 0.9649\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.1553 - acc: 0.9670 - val_loss: 0.1461 - val_acc: 0.9649\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.1399 - acc: 0.9692 - val_loss: 0.1345 - val_acc: 0.9649\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.1266 - acc: 0.9692 - val_loss: 0.1237 - val_acc: 0.9649\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.1152 - acc: 0.9736 - val_loss: 0.1139 - val_acc: 0.9649\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.1050 - acc: 0.9758 - val_loss: 0.1069 - val_acc: 0.9649\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.0967 - acc: 0.9802 - val_loss: 0.1015 - val_acc: 0.9649\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.0894 - acc: 0.9802 - val_loss: 0.0961 - val_acc: 0.9649\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.0830 - acc: 0.9846 - val_loss: 0.0920 - val_acc: 0.9649\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.0771 - acc: 0.9824 - val_loss: 0.0886 - val_acc: 0.9649\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.0722 - acc: 0.9824 - val_loss: 0.0861 - val_acc: 0.9737\n",
      "114/114 [==============================] - 0s 118us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=50,\n",
    "         validation_data=(x_test, y_test),verbose=2)\n",
    "score, acc  = model.evaluate(x_test, y_test, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.08607530848760354\n",
      "Test accuracy: 0.9736842094806203\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
